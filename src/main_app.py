from src.retrieval import load_retriever_from_disk
from src.generation import create_conversational_chain

def main():
    retriever = load_retriever_from_disk()
    qa_chain = create_conversational_chain(retriever)
    chat_history = []

    print("\n--- Aloo Sahayak is ready! Ask your questions. Type 'exit' to quit. ---")

    while True:
        query = input("\nYour Question: ")
        if query.lower() == 'exit':
            break

        result = qa_chain.invoke({
            "question": query,
            "chat_history": chat_history
        })
        
        answer = result["answer"]
        chat_history.append((query, answer))
        
        # --- NEW PART: PRINTING INTERMEDIATE STEPS ---
        print("\n" + "="*50)
        print("INTERMEDIATE STEPS")
        print("="*50)
        
        print(f"\n[INFO] Standalone Question Generated by LLM:\n'{result['generated_question']}'")
        
        print("\n[INFO] Documents Retrieved from FAISS:")
        for i, doc in enumerate(result['source_documents']):
            source = doc.metadata.get('source', 'Unknown')
            content_preview = doc.page_content[:150].replace('\n', ' ') + "..."
            print(f"  - Doc {i+1} (from {source}):\n    '{content_preview}'")
        print("="*50)
        # -----------------------------------------------

        print("\nAnswer:")
        print(answer)

if __name__ == "__main__":
    main()